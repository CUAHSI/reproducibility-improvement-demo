# CZ_ProcessesDriversPredictability

## Overview

This repository contains code and datasets associated with the manuscript
"Intensive management redefines critical zone processes, drivers, and predictability" (Goodwell et al, 2025); submitted to PNAS, March 2025.

The analysis applies Gaussian Mixture Model clustering to multivariate time-series datasets to define "temporal regimes", followed by Principal Component Analysis to characterize dominant modes of variability in each regime.  We apply information theory metrics to PC projections to determine dominant predictors of each multivariate system.

**Repository contact:** Allison Goodwell at goodwel2@illinois.edu.

### Example analysis

In lieu of running the entire analysis, we have also created an example workflow showing how we analyzed stream chemistry at just one of the sites (Monticello). This example is stored in `Example_Notebook_StreamChemistry.ipynb`.

## How to run the full codebase

### Input data

This repository contains the input datasets needed to run the code stored under the following 3 folders:

- `Data > FluxTowers`
- `Data > River`
- `Data > RootSoil`

*Full datasets for the Monticello RL stream chemistry and NEAG, NEPR soil gas concentration datasets will be uploaded upon acceptance of the manuscript. The full set of GC flux tower data is available at: https://www.hydroshare.org/resource/0ef3eda3534f44a6bbd65786d57222ea/

US-Kon Ameriflux full datasets available at: https://ameriflux.lbl.gov/sites/siteinfo/US-Kon

### Data preparation code

This code relies on the input data, some of which is not currently available but will be at the time of publication. Ultimately, they process these input datasets into analysis-ready data. 

DataPrep...py: These codes generate the "Processed" data that is used for the "Analysis" codes for each case study.  They align variables from multiple sources, do minor gap-filling and outlier removal for some variables, plot data, and drop nan values.

You can find the outputs of this data preparation code in the `Data > Processed` folder, generated by DataPrep codes that assemble original data files for each case study.

### Analysis code

This code starts with the outputs of the data preparation step, stored in this repository in `Data > Processed`. 

cluster_funcs.py: This contains all necessary functions to perform clustering, dimensionality reduction, and IT metrics and produce figures.  This is imported to each "analysis code"

Analysis...py: analysis codes for each case study (based on flux tower data, stream solute concentrations, and root-soil gas concentration datasets and meteorological and soil drivers).  The analysis codes produce several figures (deposited in FIGS folder) and a csv file summarizing the results of the information theory analysis.

### Results

The results of the analysis code are stored in the repository under a folder called `FIGS`. This folder contains figures and example data outputs.
